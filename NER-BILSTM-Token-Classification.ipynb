{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "drJclOiF-1UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O dataset_train.csv \\\n",
        "https://raw.githubusercontent.com/thoriqtau/BILSTM-Attention-CRF-for-Indonesian-Profanity/main/dataset/dataset_train.csv -qq\n",
        "\n",
        "!wget -O dataset_test.csv \\\n",
        "https://raw.githubusercontent.com/thoriqtau/BILSTM-Attention-CRF-for-Indonesian-Profanity/main/dataset/dataset_test.csv -qq\n"
      ],
      "metadata": {
        "id": "1r8VPI5c6Omq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read dataset train\n",
        "df_train = pd.read_csv(\"/content/dataset_train.csv\", header=None)\n",
        "train_data_list = df_train.iloc[:, 0].tolist()\n",
        "\n",
        "# Read dataet Test\n",
        "df_test = pd.read_csv(\"//content/dataset_test.csv\", header=None)\n",
        "test_data_list = df_test.iloc[:, 0].tolist()"
      ],
      "metadata": {
        "id": "3tZ07RI1-0F7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data Train:\\n\", train_data_list[0], \"\\n\")\n",
        "print(\"Data Train:\\n\", test_data_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN8NESPk5OMi",
        "outputId": "912b596d-755c-4459-b4d8-c7eadd289392"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Train:\n",
            " lucunya/O adalah/O kak/O pacar/O nyadain/O ini/O telat/O bgt/O guys/O gue/O rasa/O pengaruh/O mecin/O tuh/O emang/O bikin/O kita/O slow/O respon/O agak/O bolot/FIS-POS gitu/O  \n",
            "\n",
            "Data Train:\n",
            " loe/O lantas/O remehkan/O perhatian/O yang/O gue/O kasih/O khusus/O ke/O elo/O basic/O elo/O cowok/O bego/PER-POS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parsing Sentence"
      ],
      "metadata": {
        "id": "Rre_Ia_U44cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing sentence and label function\n",
        "def parse_inline_dataset(dataset):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    for line in dataset:\n",
        "        tokens = line.strip().split()\n",
        "        sentence = []\n",
        "        label_seq = []\n",
        "        for token in tokens:\n",
        "            if '/' in token:\n",
        "                word, tag = token.rsplit('/', 1)\n",
        "                sentence.append(word.lower())\n",
        "                label_seq.append(tag)\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label_seq)\n",
        "    return sentences, labels"
      ],
      "metadata": {
        "id": "NOWtqyIr9vPq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_train_sentences, all_train_labels = parse_inline_dataset(train_data_list)\n",
        "all_test_sentences, all_test_labels = parse_inline_dataset(test_data_list)"
      ],
      "metadata": {
        "id": "z9Xo7j1J5M5d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token Train Sentences:\\n\", all_train_sentences[0], \"\\n\")\n",
        "print(\"Token Train Labels:\\n\", all_train_labels[0])\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "\n",
        "print(\"Token Test Sentences:\\n\", all_test_sentences[0], \"\\n\")\n",
        "print(\"Token Test Labels:\\n\", all_test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRzNmGVk6Wec",
        "outputId": "c3a7f66d-00ed-407d-b501-d067fc2e91e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Train Sentences:\n",
            " ['lucunya', 'adalah', 'kak', 'pacar', 'nyadain', 'ini', 'telat', 'bgt', 'guys', 'gue', 'rasa', 'pengaruh', 'mecin', 'tuh', 'emang', 'bikin', 'kita', 'slow', 'respon', 'agak', 'bolot', 'gitu'] \n",
            "\n",
            "Token Train Labels:\n",
            " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'FIS-POS', 'O']\n",
            "--------------------------------------------\n",
            "Token Test Sentences:\n",
            " ['loe', 'lantas', 'remehkan', 'perhatian', 'yang', 'gue', 'kasih', 'khusus', 'ke', 'elo', 'basic', 'elo', 'cowok', 'bego'] \n",
            "\n",
            "Token Test Labels:\n",
            " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PER-POS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Vocab"
      ],
      "metadata": {
        "id": "Dm5LMetmAUkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary mapping function\n",
        "def build_vocab(sequences, specials=[\"<PAD>\", \"<UNK>\"]):\n",
        "    vocab = {tok: idx for idx, tok in enumerate(specials)}\n",
        "    for seq in sequences:\n",
        "        for item in seq:\n",
        "            if item not in vocab:\n",
        "                vocab[item] = len(vocab)\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "ppD2Hs1nAWjL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrod to index vocab\n",
        "word_to_ix = build_vocab(all_train_sentences, specials=[\"<PAD>\", \"<UNK>\"])\n",
        "# tag to index vocab\n",
        "tag_to_ix = build_vocab(all_train_labels, specials=[\"<PAD>\"])\n",
        "\n",
        "# index to word vocab\n",
        "ix_to_word = {idx: word for word, idx in word_to_ix.items()}\n",
        "# index to tag vocab\n",
        "ix_to_tag = {idx: tag for tag, idx in tag_to_ix.items()}"
      ],
      "metadata": {
        "id": "vQPrhWufAZoT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Word_to_ix (see 5):\\n\", list(word_to_ix.items())[:5], \"\\n\")\n",
        "print(\"Tag_to_ix (see 5):\\n\", list(tag_to_ix.items())[:5], \"\\n\")\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "\n",
        "print(\"Ix_to_word (see 5):\\n\", list(ix_to_word.items())[:5], \"\\n\")\n",
        "print(\"Ix_to_tag (see 5):\\n\", list(ix_to_tag.items())[:5], \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K4nJcQz7lkd",
        "outputId": "4ebf24cc-3661-4656-a06c-3394bbe7fb78"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word_to_ix (see 5):\n",
            " [('<PAD>', 0), ('<UNK>', 1), ('lucunya', 2), ('adalah', 3), ('kak', 4)] \n",
            "\n",
            "Tag_to_ix (see 5):\n",
            " [('<PAD>', 0), ('O', 1), ('FIS-POS', 2), ('PER-NEG', 3), ('SEKS-NEG', 4)] \n",
            "\n",
            "--------------------------------------------\n",
            "Ix_to_word (see 5):\n",
            " [(0, '<PAD>'), (1, '<UNK>'), (2, 'lucunya'), (3, 'adalah'), (4, 'kak')] \n",
            "\n",
            "Ix_to_tag (see 5):\n",
            " [(0, '<PAD>'), (1, 'O'), (2, 'FIS-POS'), (3, 'PER-NEG'), (4, 'SEKS-NEG')] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [[word_to_ix.get(w, word_to_ix[\"<UNK>\"]) for w in sent] for sent in all_train_sentences]\n",
        "y_train = [[tag_to_ix[l] for l in labels] for labels in all_train_labels]\n",
        "\n",
        "X_test = [[word_to_ix.get(w, word_to_ix[\"<UNK>\"]) for w in sent] for sent in all_test_sentences]\n",
        "y_test = [[tag_to_ix[l] for l in labs] for labs in all_test_labels]"
      ],
      "metadata": {
        "id": "1cCmoWJaAlf4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train (see 1):\\n\", all_train_sentences[0], \"\\n\" ,X_train[0], \"\\n\")\n",
        "print(\"y_train (see 1):\\n\", all_train_labels[0], \"\\n\" ,y_train[0], \"\\n\")\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "\n",
        "print(\"X_test (see 1):\\n\", all_train_sentences[0], \"\\n\", X_test[0], \"\\n\")\n",
        "print(\"y_test (see 1):\\n\", all_train_labels[0], \"\\n\", y_test[0], \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-oXO4Fv63ur",
        "outputId": "9dedf70f-734b-4ce3-c965-c0a5332f3fec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train (see 1):\n",
            " ['lucunya', 'adalah', 'kak', 'pacar', 'nyadain', 'ini', 'telat', 'bgt', 'guys', 'gue', 'rasa', 'pengaruh', 'mecin', 'tuh', 'emang', 'bikin', 'kita', 'slow', 'respon', 'agak', 'bolot', 'gitu'] \n",
            " [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23] \n",
            "\n",
            "y_train (see 1):\n",
            " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'FIS-POS', 'O'] \n",
            " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1] \n",
            "\n",
            "--------------------------------------------\n",
            "X_test (see 1):\n",
            " ['lucunya', 'adalah', 'kak', 'pacar', 'nyadain', 'ini', 'telat', 'bgt', 'guys', 'gue', 'rasa', 'pengaruh', 'mecin', 'tuh', 'emang', 'bikin', 'kita', 'slow', 'respon', 'agak', 'bolot', 'gitu'] \n",
            " [341, 1, 1, 1196, 60, 11, 1197, 1141, 215, 1, 1, 1, 75, 397] \n",
            "\n",
            "y_test (see 1):\n",
            " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'FIS-POS', 'O'] \n",
            " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "Z2zANUt_DDah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Create class dataloader\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            torch.tensor(self.X[idx], dtype=torch.long),\n",
        "            torch.tensor(self.y[idx], dtype=torch.long)\n",
        "        )"
      ],
      "metadata": {
        "id": "p3McVUORDDII"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Padding function\n",
        "def collate_fn(batch, pad_word_ix, pad_tag_ix):\n",
        "    sentences, labels = zip(*batch)\n",
        "\n",
        "    sentences = list(sentences)\n",
        "    labels = list(labels)\n",
        "\n",
        "    lengths = torch.tensor([len(s) for s in sentences])\n",
        "\n",
        "    padded_sentences = pad_sequence(\n",
        "        sentences,\n",
        "        batch_first=True,\n",
        "        padding_value=pad_word_ix\n",
        "    )\n",
        "\n",
        "    padded_labels = pad_sequence(\n",
        "        labels,\n",
        "        batch_first=True,\n",
        "        padding_value=pad_tag_ix\n",
        "    )\n",
        "\n",
        "    return padded_sentences, padded_labels, lengths"
      ],
      "metadata": {
        "id": "zodn-y4tD44M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from functools import partial\n",
        "\n",
        "train_dataset = NERDataset(X_train, y_train)\n",
        "test_dataset = NERDataset(X_test, y_test)\n",
        "\n",
        "collate_with_pad = partial(\n",
        "    collate_fn,\n",
        "    pad_word_ix=word_to_ix[\"<PAD>\"],\n",
        "    pad_tag_ix=tag_to_ix[\"<PAD>\"]\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=8, # Batch size 8\n",
        "    shuffle=True, # Shuffle True\n",
        "    collate_fn=collate_with_pad\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=8, # Batch size 8\n",
        "    shuffle=False, # Shuffle False\n",
        "    collate_fn=collate_with_pad\n",
        ")\n"
      ],
      "metadata": {
        "id": "Su3vaDJoD2Y5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ix_to_word for tansform index to word\n",
        "ix_to_word = {v: k for k, v in word_to_ix.items()}\n",
        "\n",
        "sentences = []\n",
        "for X_batch, y_batch, lengths in train_loader:\n",
        "    for i in range(X_batch.size(0)):\n",
        "        tokens = [\n",
        "            ix_to_word[X_batch[i, j].item()]\n",
        "            for j in range(X_batch.size(1))  # full length, include PAD\n",
        "        ]\n",
        "        sentence = \" \".join(tokens)\n",
        "        sentences.append(sentence)"
      ],
      "metadata": {
        "id": "QfL1_iF1SbpO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train (see 5):\")\n",
        "for sentence in sentences[:5]:\n",
        "  print(\" \", sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRcdayEqVFLW",
        "outputId": "061ef9fa-f92a-4714-ce10-a1fa4b39f508"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train (see 5):\n",
            "  yang juara ngibul kan junjungan kalian wahai bani kampret <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "  sini om jilatin memek nya mau ngga <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "  patung anjing hachiko di jepang menjadi simbol kesetiaan abadi <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "  kapal kita karam monyet kasihan patah hati <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "  kirain budek <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bi-LSTM Arsitektur"
      ],
      "metadata": {
        "id": "qSQ6fh91AyFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install pytorch-crf\n",
        "!pip install pytorch-crf -qq"
      ],
      "metadata": {
        "id": "eWRKKXL4GyQL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchcrf import CRF\n",
        "\n",
        "# Bi-LSTM - Attention - CRF architecture\n",
        "class BiLSTM_Attend_CRF(torch.nn.Module):\n",
        "    def __init__(self, pad_ix, tag_size, vocab_size, hidden_size, embedding_dim, heads=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Embedding layer: maps token indices to dense vectors\n",
        "        # padding_idx ensures the padding token is ignored during training\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_ix)\n",
        "\n",
        "        # Bidirectional LSTM to capture left and right context\n",
        "        # hidden_size // 2 is used because of bidirectionality\n",
        "        self.bi_lstm = torch.nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_size // 2,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        # Multi-head self-attention layer\n",
        "        # Allows the model to focus on important tokens in the sequence\n",
        "        self.multiheadattention = torch.nn.MultiheadAttention(\n",
        "            embed_dim=hidden_size,\n",
        "            num_heads=heads,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        # Linear layer to project hidden states to tag scores (emissions)\n",
        "        self.hidden2tag = torch.nn.Linear(hidden_size, tag_size)\n",
        "        # CRF layer to model dependencies between output tags\n",
        "        self.crf = CRF(num_tags=tag_size, batch_first=True)\n",
        "        # Layer normalization for training stability\n",
        "        self.layer_norm = torch.nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        # Initialize hidden and cell states for BiLSTM\n",
        "        # 2 corresponds to bidirectional LSTM\n",
        "        return (\n",
        "            torch.randn(2, batch_size, self.hidden_size // 2, device=device),\n",
        "            torch.randn(2, batch_size, self.hidden_size // 2, device=device)\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp shape: (batch_size, sequence_length)\n",
        "        batch_size = inp.size(0)\n",
        "        device = inp.device\n",
        "\n",
        "        # Convert token indices to embeddings\n",
        "        embeds = self.embedding(inp)\n",
        "\n",
        "        # Initialize LSTM hidden states\n",
        "        hidden = self.init_hidden(batch_size, device)\n",
        "\n",
        "        # BiLSTM forward pass\n",
        "        lstm_out, _ = self.bi_lstm(embeds, hidden)\n",
        "\n",
        "        # Normalize LSTM outputs\n",
        "        lstm_out = self.layer_norm(lstm_out)\n",
        "\n",
        "        # Self-attention mechanism\n",
        "        # Query, key, and value are all LSTM outputs\n",
        "        attn_output, _ = self.multiheadattention(lstm_out, lstm_out, lstm_out)\n",
        "\n",
        "        # Residual connection to preserve original LSTM information\n",
        "        attn_output = attn_output + lstm_out\n",
        "\n",
        "        # Project features to tag space (emission scores)\n",
        "        logits = self.hidden2tag(attn_output)\n",
        "        return logits\n",
        "\n",
        "    def crf_neg_log_likelihood(self, inp, tags, mask=None):\n",
        "        # Compute emission scores\n",
        "        logits = self.forward(inp)\n",
        "\n",
        "        # Create mask to ignore padding tokens if not provided\n",
        "        if mask is None:\n",
        "            pad = torch.tensor(0, device=tags.device)\n",
        "            mask = tags.ne(pad)\n",
        "        # Negative log-likelihood loss for CRF\n",
        "        return -self.crf(logits, tags, mask=mask, reduction='sum')\n",
        "\n",
        "    def crf_decode(self, inp, mask=None):\n",
        "        # Compute emission scores\n",
        "        logits = self.forward(inp)\n",
        "\n",
        "        # Create mask based on input padding if not provided\n",
        "        if mask is None:\n",
        "            pad = torch.tensor(0, device=inp.device)\n",
        "            mask = inp.ne(pad)\n",
        "        # Decode the best tag sequence using Viterbi algorithm\n",
        "        return self.crf.decode(logits, mask=mask)\n"
      ],
      "metadata": {
        "id": "tv2mFpbJAx47"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train step function"
      ],
      "metadata": {
        "id": "1fFQYaodJjbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, dataloader, optimizer, device):\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    # Iterate over batches from the dataloader\n",
        "    # Each batch contains input tokens, and labels\n",
        "    for X_batch, y_batch, _ in dataloader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # Create mask: True for valid (non-padding) tokens\n",
        "        # Padding token is assumed to have index 0\n",
        "        mask = X_batch.ne(0)\n",
        "\n",
        "        # Reset gradients from the previous step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute negative log-likelihood loss from the CRF layer\n",
        "        loss = model.crf_neg_log_likelihood(\n",
        "            inp=X_batch,\n",
        "            tags=y_batch,\n",
        "            mask=mask\n",
        "        )\n",
        "\n",
        "        # Backpropagate gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate batch loss\n",
        "        total_loss += loss.item()\n",
        "    # Return average loss per batch\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "2xEANaoVHT_B"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test step function"
      ],
      "metadata": {
        "id": "Qpn-tf_YJnDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model, dataloader, device):\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    all_preds = []    # Store predicted tag sequences\n",
        "    all_labels = []   # Store ground-truth tag sequences\n",
        "\n",
        "    # Disable gradient computation for evaluation\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch, _ in dataloader:\n",
        "            # Move batch data to the selected device\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            # Create mask to ignore padding tokens\n",
        "            mask = X_batch.ne(0)\n",
        "\n",
        "            # Compute CRF negative log-likelihood loss\n",
        "            loss = model.crf_neg_log_likelihood(\n",
        "                inp=X_batch,\n",
        "                tags=y_batch,\n",
        "                mask=mask\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Decode the best tag sequence using CRF (Viterbi decoding)\n",
        "            predictions = model.crf_decode(\n",
        "                X_batch,\n",
        "                mask=mask\n",
        "            )\n",
        "\n",
        "            # Collect predictions and labels without padding\n",
        "            for pred_seq, true_seq, m in zip(predictions, y_batch, mask):\n",
        "                # Number of valid (non-padding) tokens\n",
        "                valid_len = m.sum().item()\n",
        "\n",
        "                # Truncate predictions and labels to valid length\n",
        "                all_preds.append(pred_seq[:valid_len])\n",
        "                all_labels.append(true_seq[:valid_len].cpu().tolist())\n",
        "\n",
        "    # Compute average loss per batch\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss, all_preds, all_labels"
      ],
      "metadata": {
        "id": "2ICB51fHHgaB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dictionary Entity"
      ],
      "metadata": {
        "id": "6ab1dKweJxGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entity_dict(tag_to_ix):\n",
        "    # Define entity labels to be evaluated (exclude \"O\" and non-entity tags)\n",
        "    entity_labels = [\n",
        "        tag_to_ix[\"PER-POS\"],   # Person - Positive\n",
        "        tag_to_ix[\"PER-NEG\"],   # Person - Negative\n",
        "        tag_to_ix[\"HWN-POS\"],   # Animal - Positive\n",
        "        tag_to_ix[\"HWN-NEG\"],   # Animal - Negative\n",
        "        tag_to_ix[\"FIS-POS\"],   # Physical - Positive\n",
        "        tag_to_ix[\"FIS-NEG\"],   # Physical - Negative\n",
        "        tag_to_ix[\"SEKS-NEG\"],  # Sexual - Negative\n",
        "    ]\n",
        "\n",
        "    # Initialize metric containers for each entity label\n",
        "    metrics = {\n",
        "        label: {\n",
        "            \"TP\": 0,            # True Positives\n",
        "            \"FP\": 0,            # False Positives\n",
        "            \"FN\": 0,            # False Negatives\n",
        "            \"Precision\": 0.0,   # Precision score\n",
        "            \"Recall\": 0.0,      # Recall score\n",
        "            \"F1-Score\": 0.0,    # F1-score\n",
        "            \"Support\": 0,       # Number of true occurrences\n",
        "        }\n",
        "        for label in entity_labels\n",
        "    }\n",
        "    return metrics, entity_labels"
      ],
      "metadata": {
        "id": "xsrb95V_39jU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric Function"
      ],
      "metadata": {
        "id": "hNpFw5rEKG7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import copy\n",
        "\n",
        "# Compute precision score\n",
        "def precision_score(tp, fp):\n",
        "  return tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "\n",
        "# Compute recall score\n",
        "def recall_score(tp, fn):\n",
        "    return tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "\n",
        "# Compute F1-score from precision and recall\n",
        "def f1_score(p, r):\n",
        "    return 2 * p * r / (p + r) if (p + r) > 0 else 0.0\n",
        "\n",
        "# Flatten a list of sequences into a single list\n",
        "def flatten(seqs):\n",
        "    return [x for seq in seqs for x in seq]\n",
        "\n",
        "# Compute TP, FP, and FN for each entity label (token-level)\n",
        "def compute_tp_fp_fn(preds, labels, entity_score_dict, entity_labels):\n",
        "    y_true = flatten(labels)\n",
        "    y_pred = flatten(preds)\n",
        "\n",
        "    # Deep copy to avoid modifying the original dictionary\n",
        "    score_dict = copy.deepcopy(entity_score_dict)\n",
        "\n",
        "    # Iterate over each predicted and true label pair\n",
        "    for t, p in zip(y_true, y_pred):\n",
        "        # Count support for each entity\n",
        "        if t in entity_labels:\n",
        "            score_dict[t][\"Support\"] += 1\n",
        "        # Update True Positive and False Positive counts\n",
        "        if p in entity_labels:\n",
        "            if t == p:\n",
        "                score_dict[p][\"TP\"] += 1  # True Positive\n",
        "            else:\n",
        "                score_dict[p][\"FP\"] += 1  # False Positive\n",
        "        # Update False Negative count\n",
        "        if t in entity_labels and t != p:\n",
        "            score_dict[t][\"FN\"] += 1  # False Negative\n",
        "\n",
        "    # Compute precision, recall, and F1-score for each entity label\n",
        "    for label in entity_labels:\n",
        "        tp = score_dict[label][\"TP\"]\n",
        "        fp = score_dict[label][\"FP\"]\n",
        "        fn = score_dict[label][\"FN\"]\n",
        "\n",
        "        p = precision_score(tp, fp)\n",
        "        r = recall_score(tp, fn)\n",
        "        f1 = f1_score(p, r)\n",
        "\n",
        "        score_dict[label][\"Precision\"] = p\n",
        "        score_dict[label][\"Recall\"] = r\n",
        "        score_dict[label][\"F1-Score\"] = f1\n",
        "    return score_dict\n",
        "\n",
        "# Compute micro-averaged token-level precision, recall, and F1-score\n",
        "def compute_token_f1(preds, labels, entity_labels):\n",
        "    # Flatten predicted and true label sequences\n",
        "    y_true = flatten(labels)\n",
        "    y_pred = flatten(preds)\n",
        "\n",
        "    # Compute micro-averaged metrics\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        labels=entity_labels,\n",
        "        average=\"micro\",\n",
        "        zero_division=0\n",
        "    )\n",
        "    return precision, recall, f1"
      ],
      "metadata": {
        "id": "7nvqi6kX9vAd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    checkpoints,\n",
        "    epochs,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    optimizer,\n",
        "    device,\n",
        "    entity_metric_dict,\n",
        "    entity_labels,\n",
        "):\n",
        "    best_metric = 0.0\n",
        "\n",
        "    # Initialize entity-level metric containers\n",
        "    entity_metric = entity_metric_dict\n",
        "    entity = entity_labels\n",
        "\n",
        "    # Training loop over epochs\n",
        "    for epoch in range(epochs):\n",
        "        # Perform one training epoch\n",
        "        train_loss = train_step(model, train_loader, optimizer, device)\n",
        "\n",
        "        # Evaluate model\n",
        "        test_loss, preds, labels = test_step(model, test_loader, device)\n",
        "\n",
        "        # Compute TP, FP, and FN for each entity label\n",
        "        score_dict = compute_tp_fp_fn(preds, labels, entity_metric, entity)\n",
        "\n",
        "        # Compute overall token-level precision, recall, and F1-score\n",
        "        precision, recall, f1 = compute_token_f1(preds, labels, entity)\n",
        "\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"EPOCH [{epoch+1}/{epochs}]\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {test_loss:.4f}\")\n",
        "        print(\n",
        "            f\"Overall - Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Save the model checkpoint if current F1-score is the best\n",
        "        if f1 > best_metric:\n",
        "            best_metric = f1\n",
        "            checkpoint = {\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"pad_ix\": checkpoints[\"pad_ix\"],\n",
        "                \"tag_size\": checkpoints[\"tag_size\"],\n",
        "                \"vocab_size\": checkpoints[\"vocab_size\"],\n",
        "                \"hidden_size\": checkpoints[\"hidden_size\"],\n",
        "                \"embedding_dim\": checkpoints[\"embedding_dim\"],\n",
        "                \"heads\": checkpoints[\"heads\"],\n",
        "                \"word_to_ix\": checkpoints[\"word_to_ix\"],\n",
        "                \"tag_to_ix\": checkpoints[\"tag_to_ix\"],\n",
        "                \"ix_to_word\": checkpoints[\"ix_to_word\"],\n",
        "                \"ix_to_tag\": checkpoints[\"ix_to_tag\"],\n",
        "            }\n",
        "            torch.save(checkpoint, \"best_model.sav\")\n",
        "    print(f\"âœ” Model terbaik disimpan dengan F1-Score: {best_metric:.4f}\\n\")\n",
        "    return score_dict"
      ],
      "metadata": {
        "id": "WxcSRCTZH71A"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Model"
      ],
      "metadata": {
        "id": "OAzS0qVxE2J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {\n",
        "    \"pad_ix\": word_to_ix[\"<PAD>\"],\n",
        "    \"tag_size\": len(tag_to_ix),\n",
        "    \"vocab_size\": len(word_to_ix),\n",
        "    \"hidden_size\": 256,\n",
        "    \"embedding_dim\": 200,\n",
        "    \"heads\": 4,\n",
        "    \"word_to_ix\": word_to_ix,\n",
        "    \"tag_to_ix\": tag_to_ix,\n",
        "    \"ix_to_word\": ix_to_word,\n",
        "    \"ix_to_tag\": ix_to_tag,\n",
        "}"
      ],
      "metadata": {
        "id": "Qw9bWnEUK386"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting default device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the BiLSTM-Attention-CRF model\n",
        "model = BiLSTM_Attend_CRF(\n",
        "    pad_ix=checkpoint[\"pad_ix\"],\n",
        "    tag_size=checkpoint[\"tag_size\"],\n",
        "    vocab_size=checkpoint[\"vocab_size\"],\n",
        "    hidden_size=checkpoint[\"hidden_size\"],\n",
        "    embedding_dim=checkpoint[\"embedding_dim\"],\n",
        "    heads=checkpoint[\"heads\"],\n",
        ").to(device)\n",
        "\n",
        "# AdamW optimizer and learning rate 0.001\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "WSlioKTJHM3Y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 200\n",
        "entity_metric_dict, entity_labels = entity_dict(tag_to_ix)\n",
        "\n",
        "score_dict = train_model(\n",
        "    model=model,\n",
        "    checkpoints=checkpoint,\n",
        "    epochs=epochs,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    entity_metric_dict=entity_metric_dict,\n",
        "    entity_labels=entity_labels,\n",
        ")"
      ],
      "metadata": {
        "id": "8UyT6wtLXuMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a58953-64c5-4207-85e2-1c59f18f56ef"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "EPOCH [1/200]\n",
            "================================================================================\n",
            "Train Loss: 38.5256 | Val Loss: 32.2159\n",
            "Overall - Precision: 0.7692 | Recall: 0.4225 | F1: 0.5455\n",
            "================================================================================\n",
            "EPOCH [2/200]\n",
            "================================================================================\n",
            "Train Loss: 9.0036 | Val Loss: 26.5299\n",
            "Overall - Precision: 0.7273 | Recall: 0.5634 | F1: 0.6349\n",
            "================================================================================\n",
            "EPOCH [3/200]\n",
            "================================================================================\n",
            "Train Loss: 3.2707 | Val Loss: 31.3580\n",
            "Overall - Precision: 0.6964 | Recall: 0.5493 | F1: 0.6142\n",
            "================================================================================\n",
            "EPOCH [4/200]\n",
            "================================================================================\n",
            "Train Loss: 1.7904 | Val Loss: 34.8335\n",
            "Overall - Precision: 0.6429 | Recall: 0.5070 | F1: 0.5669\n",
            "================================================================================\n",
            "EPOCH [5/200]\n",
            "================================================================================\n",
            "Train Loss: 0.9766 | Val Loss: 43.3547\n",
            "Overall - Precision: 0.6964 | Recall: 0.5493 | F1: 0.6142\n",
            "================================================================================\n",
            "EPOCH [6/200]\n",
            "================================================================================\n",
            "Train Loss: 0.4925 | Val Loss: 44.1848\n",
            "Overall - Precision: 0.7455 | Recall: 0.5775 | F1: 0.6508\n",
            "================================================================================\n",
            "EPOCH [7/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2204 | Val Loss: 47.8643\n",
            "Overall - Precision: 0.7091 | Recall: 0.5493 | F1: 0.6190\n",
            "================================================================================\n",
            "EPOCH [8/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1778 | Val Loss: 50.4850\n",
            "Overall - Precision: 0.7500 | Recall: 0.5915 | F1: 0.6614\n",
            "================================================================================\n",
            "EPOCH [9/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2032 | Val Loss: 46.0826\n",
            "Overall - Precision: 0.7500 | Recall: 0.5915 | F1: 0.6614\n",
            "================================================================================\n",
            "EPOCH [10/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1626 | Val Loss: 58.4892\n",
            "Overall - Precision: 0.7143 | Recall: 0.5634 | F1: 0.6299\n",
            "================================================================================\n",
            "EPOCH [11/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1414 | Val Loss: 57.5535\n",
            "Overall - Precision: 0.7222 | Recall: 0.5493 | F1: 0.6240\n",
            "================================================================================\n",
            "EPOCH [12/200]\n",
            "================================================================================\n",
            "Train Loss: 0.3140 | Val Loss: 53.4401\n",
            "Overall - Precision: 0.7018 | Recall: 0.5634 | F1: 0.6250\n",
            "================================================================================\n",
            "EPOCH [13/200]\n",
            "================================================================================\n",
            "Train Loss: 1.0750 | Val Loss: 42.2047\n",
            "Overall - Precision: 0.7193 | Recall: 0.5775 | F1: 0.6406\n",
            "================================================================================\n",
            "EPOCH [14/200]\n",
            "================================================================================\n",
            "Train Loss: 1.1901 | Val Loss: 34.9834\n",
            "Overall - Precision: 0.7143 | Recall: 0.5634 | F1: 0.6299\n",
            "================================================================================\n",
            "EPOCH [15/200]\n",
            "================================================================================\n",
            "Train Loss: 0.6552 | Val Loss: 43.8947\n",
            "Overall - Precision: 0.6842 | Recall: 0.5493 | F1: 0.6094\n",
            "================================================================================\n",
            "EPOCH [16/200]\n",
            "================================================================================\n",
            "Train Loss: 0.4228 | Val Loss: 40.3751\n",
            "Overall - Precision: 0.6897 | Recall: 0.5634 | F1: 0.6202\n",
            "================================================================================\n",
            "EPOCH [17/200]\n",
            "================================================================================\n",
            "Train Loss: 0.3270 | Val Loss: 42.9973\n",
            "Overall - Precision: 0.7895 | Recall: 0.6338 | F1: 0.7031\n",
            "================================================================================\n",
            "EPOCH [18/200]\n",
            "================================================================================\n",
            "Train Loss: 1.4828 | Val Loss: 45.7048\n",
            "Overall - Precision: 0.7593 | Recall: 0.5775 | F1: 0.6560\n",
            "================================================================================\n",
            "EPOCH [19/200]\n",
            "================================================================================\n",
            "Train Loss: 1.6038 | Val Loss: 78.9521\n",
            "Overall - Precision: 0.7037 | Recall: 0.5352 | F1: 0.6080\n",
            "================================================================================\n",
            "EPOCH [20/200]\n",
            "================================================================================\n",
            "Train Loss: 1.5113 | Val Loss: 42.2338\n",
            "Overall - Precision: 0.7069 | Recall: 0.5775 | F1: 0.6357\n",
            "================================================================================\n",
            "EPOCH [21/200]\n",
            "================================================================================\n",
            "Train Loss: 1.2529 | Val Loss: 50.8848\n",
            "Overall - Precision: 0.7358 | Recall: 0.5493 | F1: 0.6290\n",
            "================================================================================\n",
            "EPOCH [22/200]\n",
            "================================================================================\n",
            "Train Loss: 2.4115 | Val Loss: 52.7528\n",
            "Overall - Precision: 0.7500 | Recall: 0.5915 | F1: 0.6614\n",
            "================================================================================\n",
            "EPOCH [23/200]\n",
            "================================================================================\n",
            "Train Loss: 1.2413 | Val Loss: 38.0672\n",
            "Overall - Precision: 0.7544 | Recall: 0.6056 | F1: 0.6719\n",
            "================================================================================\n",
            "EPOCH [24/200]\n",
            "================================================================================\n",
            "Train Loss: 0.5110 | Val Loss: 56.8359\n",
            "Overall - Precision: 0.7091 | Recall: 0.5493 | F1: 0.6190\n",
            "================================================================================\n",
            "EPOCH [25/200]\n",
            "================================================================================\n",
            "Train Loss: 0.3890 | Val Loss: 45.8545\n",
            "Overall - Precision: 0.7241 | Recall: 0.5915 | F1: 0.6512\n",
            "================================================================================\n",
            "EPOCH [26/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1453 | Val Loss: 50.9065\n",
            "Overall - Precision: 0.7544 | Recall: 0.6056 | F1: 0.6719\n",
            "================================================================================\n",
            "EPOCH [27/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2583 | Val Loss: 46.6914\n",
            "Overall - Precision: 0.7288 | Recall: 0.6056 | F1: 0.6615\n",
            "================================================================================\n",
            "EPOCH [28/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2513 | Val Loss: 49.8446\n",
            "Overall - Precision: 0.7544 | Recall: 0.6056 | F1: 0.6719\n",
            "================================================================================\n",
            "EPOCH [29/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2252 | Val Loss: 46.2510\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [30/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2340 | Val Loss: 53.4074\n",
            "Overall - Precision: 0.8000 | Recall: 0.6197 | F1: 0.6984\n",
            "================================================================================\n",
            "EPOCH [31/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0828 | Val Loss: 53.0112\n",
            "Overall - Precision: 0.7193 | Recall: 0.5775 | F1: 0.6406\n",
            "================================================================================\n",
            "EPOCH [32/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0212 | Val Loss: 54.4674\n",
            "Overall - Precision: 0.7193 | Recall: 0.5775 | F1: 0.6406\n",
            "================================================================================\n",
            "EPOCH [33/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0656 | Val Loss: 58.9585\n",
            "Overall - Precision: 0.7368 | Recall: 0.5915 | F1: 0.6562\n",
            "================================================================================\n",
            "EPOCH [34/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0768 | Val Loss: 57.6147\n",
            "Overall - Precision: 0.7636 | Recall: 0.5915 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [35/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0230 | Val Loss: 55.3627\n",
            "Overall - Precision: 0.7321 | Recall: 0.5775 | F1: 0.6457\n",
            "================================================================================\n",
            "EPOCH [36/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0239 | Val Loss: 55.9078\n",
            "Overall - Precision: 0.7500 | Recall: 0.5915 | F1: 0.6614\n",
            "================================================================================\n",
            "EPOCH [37/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0186 | Val Loss: 54.5962\n",
            "Overall - Precision: 0.7857 | Recall: 0.6197 | F1: 0.6929\n",
            "================================================================================\n",
            "EPOCH [38/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0389 | Val Loss: 60.3346\n",
            "Overall - Precision: 0.7818 | Recall: 0.6056 | F1: 0.6825\n",
            "================================================================================\n",
            "EPOCH [39/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0080 | Val Loss: 58.8037\n",
            "Overall - Precision: 0.7679 | Recall: 0.6056 | F1: 0.6772\n",
            "================================================================================\n",
            "EPOCH [40/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0110 | Val Loss: 59.7345\n",
            "Overall - Precision: 0.7500 | Recall: 0.5915 | F1: 0.6614\n",
            "================================================================================\n",
            "EPOCH [41/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0181 | Val Loss: 59.0019\n",
            "Overall - Precision: 0.7321 | Recall: 0.5775 | F1: 0.6457\n",
            "================================================================================\n",
            "EPOCH [42/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0117 | Val Loss: 63.5529\n",
            "Overall - Precision: 0.7321 | Recall: 0.5775 | F1: 0.6457\n",
            "================================================================================\n",
            "EPOCH [43/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0132 | Val Loss: 62.0050\n",
            "Overall - Precision: 0.7500 | Recall: 0.5915 | F1: 0.6614\n",
            "================================================================================\n",
            "EPOCH [44/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0802 | Val Loss: 60.5238\n",
            "Overall - Precision: 0.7500 | Recall: 0.5915 | F1: 0.6614\n",
            "================================================================================\n",
            "EPOCH [45/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0143 | Val Loss: 59.4997\n",
            "Overall - Precision: 0.7321 | Recall: 0.5775 | F1: 0.6457\n",
            "================================================================================\n",
            "EPOCH [46/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0084 | Val Loss: 59.4465\n",
            "Overall - Precision: 0.7143 | Recall: 0.5634 | F1: 0.6299\n",
            "================================================================================\n",
            "EPOCH [47/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0154 | Val Loss: 57.8780\n",
            "Overall - Precision: 0.7321 | Recall: 0.5775 | F1: 0.6457\n",
            "================================================================================\n",
            "EPOCH [48/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0061 | Val Loss: 59.1867\n",
            "Overall - Precision: 0.7500 | Recall: 0.5915 | F1: 0.6614\n",
            "================================================================================\n",
            "EPOCH [49/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0204 | Val Loss: 59.3976\n",
            "Overall - Precision: 0.7321 | Recall: 0.5775 | F1: 0.6457\n",
            "================================================================================\n",
            "EPOCH [50/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0076 | Val Loss: 56.2085\n",
            "Overall - Precision: 0.7143 | Recall: 0.5634 | F1: 0.6299\n",
            "================================================================================\n",
            "EPOCH [51/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0413 | Val Loss: 61.5363\n",
            "Overall - Precision: 0.7818 | Recall: 0.6056 | F1: 0.6825\n",
            "================================================================================\n",
            "EPOCH [52/200]\n",
            "================================================================================\n",
            "Train Loss: 0.6447 | Val Loss: 75.2777\n",
            "Overall - Precision: 0.7778 | Recall: 0.5915 | F1: 0.6720\n",
            "================================================================================\n",
            "EPOCH [53/200]\n",
            "================================================================================\n",
            "Train Loss: 1.0778 | Val Loss: 65.1703\n",
            "Overall - Precision: 0.7170 | Recall: 0.5352 | F1: 0.6129\n",
            "================================================================================\n",
            "EPOCH [54/200]\n",
            "================================================================================\n",
            "Train Loss: 2.2708 | Val Loss: 39.1060\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [55/200]\n",
            "================================================================================\n",
            "Train Loss: 2.0448 | Val Loss: 83.7973\n",
            "Overall - Precision: 0.7018 | Recall: 0.5634 | F1: 0.6250\n",
            "================================================================================\n",
            "EPOCH [56/200]\n",
            "================================================================================\n",
            "Train Loss: 3.4216 | Val Loss: 41.6435\n",
            "Overall - Precision: 0.7719 | Recall: 0.6197 | F1: 0.6875\n",
            "================================================================================\n",
            "EPOCH [57/200]\n",
            "================================================================================\n",
            "Train Loss: 3.9873 | Val Loss: 38.8049\n",
            "Overall - Precision: 0.7213 | Recall: 0.6197 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [58/200]\n",
            "================================================================================\n",
            "Train Loss: 5.8901 | Val Loss: 126.4439\n",
            "Overall - Precision: 0.6364 | Recall: 0.3944 | F1: 0.4870\n",
            "================================================================================\n",
            "EPOCH [59/200]\n",
            "================================================================================\n",
            "Train Loss: 2.4862 | Val Loss: 44.4881\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [60/200]\n",
            "================================================================================\n",
            "Train Loss: 1.4875 | Val Loss: 94.3589\n",
            "Overall - Precision: 0.7636 | Recall: 0.5915 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [61/200]\n",
            "================================================================================\n",
            "Train Loss: 1.0517 | Val Loss: 46.0976\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [62/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1103 | Val Loss: 50.8704\n",
            "Overall - Precision: 0.7719 | Recall: 0.6197 | F1: 0.6875\n",
            "================================================================================\n",
            "EPOCH [63/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1885 | Val Loss: 46.8897\n",
            "Overall - Precision: 0.7458 | Recall: 0.6197 | F1: 0.6769\n",
            "================================================================================\n",
            "EPOCH [64/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1194 | Val Loss: 56.1536\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [65/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0463 | Val Loss: 58.1099\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [66/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0563 | Val Loss: 58.3449\n",
            "Overall - Precision: 0.7018 | Recall: 0.5634 | F1: 0.6250\n",
            "================================================================================\n",
            "EPOCH [67/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0132 | Val Loss: 57.8440\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [68/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0576 | Val Loss: 57.7956\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [69/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1734 | Val Loss: 62.6346\n",
            "Overall - Precision: 0.6897 | Recall: 0.5634 | F1: 0.6202\n",
            "================================================================================\n",
            "EPOCH [70/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1026 | Val Loss: 64.8470\n",
            "Overall - Precision: 0.6964 | Recall: 0.5493 | F1: 0.6142\n",
            "================================================================================\n",
            "EPOCH [71/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0396 | Val Loss: 69.4430\n",
            "Overall - Precision: 0.7368 | Recall: 0.5915 | F1: 0.6562\n",
            "================================================================================\n",
            "EPOCH [72/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0311 | Val Loss: 70.2241\n",
            "Overall - Precision: 0.7818 | Recall: 0.6056 | F1: 0.6825\n",
            "================================================================================\n",
            "EPOCH [73/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0117 | Val Loss: 69.4137\n",
            "Overall - Precision: 0.7143 | Recall: 0.5634 | F1: 0.6299\n",
            "================================================================================\n",
            "EPOCH [74/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2964 | Val Loss: 68.9081\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [75/200]\n",
            "================================================================================\n",
            "Train Loss: 0.7143 | Val Loss: 73.8166\n",
            "Overall - Precision: 0.7857 | Recall: 0.6197 | F1: 0.6929\n",
            "================================================================================\n",
            "EPOCH [76/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1434 | Val Loss: 65.2952\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [77/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0563 | Val Loss: 70.4304\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [78/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0129 | Val Loss: 67.6488\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [79/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1319 | Val Loss: 64.9850\n",
            "Overall - Precision: 0.7719 | Recall: 0.6197 | F1: 0.6875\n",
            "================================================================================\n",
            "EPOCH [80/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0443 | Val Loss: 70.4372\n",
            "Overall - Precision: 0.8276 | Recall: 0.6761 | F1: 0.7442\n",
            "================================================================================\n",
            "EPOCH [81/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0284 | Val Loss: 74.3880\n",
            "Overall - Precision: 0.7500 | Recall: 0.5915 | F1: 0.6614\n",
            "================================================================================\n",
            "EPOCH [82/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0155 | Val Loss: 74.1054\n",
            "Overall - Precision: 0.7895 | Recall: 0.6338 | F1: 0.7031\n",
            "================================================================================\n",
            "EPOCH [83/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0299 | Val Loss: 72.5495\n",
            "Overall - Precision: 0.7368 | Recall: 0.5915 | F1: 0.6562\n",
            "================================================================================\n",
            "EPOCH [84/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0854 | Val Loss: 70.4769\n",
            "Overall - Precision: 0.7719 | Recall: 0.6197 | F1: 0.6875\n",
            "================================================================================\n",
            "EPOCH [85/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1077 | Val Loss: 58.5482\n",
            "Overall - Precision: 0.7719 | Recall: 0.6197 | F1: 0.6875\n",
            "================================================================================\n",
            "EPOCH [86/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1666 | Val Loss: 77.5882\n",
            "Overall - Precision: 0.7544 | Recall: 0.6056 | F1: 0.6719\n",
            "================================================================================\n",
            "EPOCH [87/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0074 | Val Loss: 77.3901\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [88/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0113 | Val Loss: 78.5759\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [89/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0094 | Val Loss: 78.3260\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [90/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0134 | Val Loss: 72.9408\n",
            "Overall - Precision: 0.7895 | Recall: 0.6338 | F1: 0.7031\n",
            "================================================================================\n",
            "EPOCH [91/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0061 | Val Loss: 74.8132\n",
            "Overall - Precision: 0.8070 | Recall: 0.6479 | F1: 0.7188\n",
            "================================================================================\n",
            "EPOCH [92/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0059 | Val Loss: 76.2451\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [93/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0052 | Val Loss: 75.9295\n",
            "Overall - Precision: 0.7544 | Recall: 0.6056 | F1: 0.6719\n",
            "================================================================================\n",
            "EPOCH [94/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0061 | Val Loss: 75.5920\n",
            "Overall - Precision: 0.7544 | Recall: 0.6056 | F1: 0.6719\n",
            "================================================================================\n",
            "EPOCH [95/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0045 | Val Loss: 77.7228\n",
            "Overall - Precision: 0.7321 | Recall: 0.5775 | F1: 0.6457\n",
            "================================================================================\n",
            "EPOCH [96/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0191 | Val Loss: 75.0362\n",
            "Overall - Precision: 0.7719 | Recall: 0.6197 | F1: 0.6875\n",
            "================================================================================\n",
            "EPOCH [97/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0109 | Val Loss: 73.4153\n",
            "Overall - Precision: 0.7368 | Recall: 0.5915 | F1: 0.6562\n",
            "================================================================================\n",
            "EPOCH [98/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0057 | Val Loss: 73.1095\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [99/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0046 | Val Loss: 73.3948\n",
            "Overall - Precision: 0.7544 | Recall: 0.6056 | F1: 0.6719\n",
            "================================================================================\n",
            "EPOCH [100/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0131 | Val Loss: 73.9070\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [101/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0118 | Val Loss: 68.1823\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [102/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0037 | Val Loss: 67.9774\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [103/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0084 | Val Loss: 68.1882\n",
            "Overall - Precision: 0.7544 | Recall: 0.6056 | F1: 0.6719\n",
            "================================================================================\n",
            "EPOCH [104/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0094 | Val Loss: 72.0296\n",
            "Overall - Precision: 0.7241 | Recall: 0.5915 | F1: 0.6512\n",
            "================================================================================\n",
            "EPOCH [105/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0035 | Val Loss: 69.7387\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [106/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0072 | Val Loss: 71.6065\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [107/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0063 | Val Loss: 70.7167\n",
            "Overall - Precision: 0.7544 | Recall: 0.6056 | F1: 0.6719\n",
            "================================================================================\n",
            "EPOCH [108/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0395 | Val Loss: 96.7670\n",
            "Overall - Precision: 0.7193 | Recall: 0.5775 | F1: 0.6406\n",
            "================================================================================\n",
            "EPOCH [109/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1695 | Val Loss: 88.7139\n",
            "Overall - Precision: 0.4912 | Recall: 0.3944 | F1: 0.4375\n",
            "================================================================================\n",
            "EPOCH [110/200]\n",
            "================================================================================\n",
            "Train Loss: 2.4539 | Val Loss: 81.1397\n",
            "Overall - Precision: 0.7547 | Recall: 0.5634 | F1: 0.6452\n",
            "================================================================================\n",
            "EPOCH [111/200]\n",
            "================================================================================\n",
            "Train Loss: 2.3721 | Val Loss: 67.1550\n",
            "Overall - Precision: 0.7193 | Recall: 0.5775 | F1: 0.6406\n",
            "================================================================================\n",
            "EPOCH [112/200]\n",
            "================================================================================\n",
            "Train Loss: 4.7811 | Val Loss: 62.3004\n",
            "Overall - Precision: 0.5424 | Recall: 0.4507 | F1: 0.4923\n",
            "================================================================================\n",
            "EPOCH [113/200]\n",
            "================================================================================\n",
            "Train Loss: 1.5408 | Val Loss: 87.1676\n",
            "Overall - Precision: 0.6226 | Recall: 0.4648 | F1: 0.5323\n",
            "================================================================================\n",
            "EPOCH [114/200]\n",
            "================================================================================\n",
            "Train Loss: 1.6511 | Val Loss: 66.7920\n",
            "Overall - Precision: 0.6167 | Recall: 0.5211 | F1: 0.5649\n",
            "================================================================================\n",
            "EPOCH [115/200]\n",
            "================================================================================\n",
            "Train Loss: 1.6357 | Val Loss: 72.6732\n",
            "Overall - Precision: 0.6935 | Recall: 0.6056 | F1: 0.6466\n",
            "================================================================================\n",
            "EPOCH [116/200]\n",
            "================================================================================\n",
            "Train Loss: 0.5088 | Val Loss: 72.2865\n",
            "Overall - Precision: 0.7241 | Recall: 0.5915 | F1: 0.6512\n",
            "================================================================================\n",
            "EPOCH [117/200]\n",
            "================================================================================\n",
            "Train Loss: 0.5086 | Val Loss: 81.2977\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [118/200]\n",
            "================================================================================\n",
            "Train Loss: 0.8156 | Val Loss: 66.4434\n",
            "Overall - Precision: 0.7627 | Recall: 0.6338 | F1: 0.6923\n",
            "================================================================================\n",
            "EPOCH [119/200]\n",
            "================================================================================\n",
            "Train Loss: 0.6794 | Val Loss: 52.8480\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [120/200]\n",
            "================================================================================\n",
            "Train Loss: 1.0001 | Val Loss: 57.2985\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [121/200]\n",
            "================================================================================\n",
            "Train Loss: 0.6005 | Val Loss: 51.3989\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [122/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2109 | Val Loss: 54.8199\n",
            "Overall - Precision: 0.7241 | Recall: 0.5915 | F1: 0.6512\n",
            "================================================================================\n",
            "EPOCH [123/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1161 | Val Loss: 56.0340\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [124/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0206 | Val Loss: 56.1144\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [125/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0151 | Val Loss: 56.1548\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [126/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0212 | Val Loss: 59.4840\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [127/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0176 | Val Loss: 60.9273\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [128/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0179 | Val Loss: 60.1488\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [129/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0232 | Val Loss: 63.9621\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [130/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0239 | Val Loss: 62.8222\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [131/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0075 | Val Loss: 61.9415\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [132/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0178 | Val Loss: 62.6639\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [133/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0104 | Val Loss: 62.7244\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [134/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0057 | Val Loss: 64.2664\n",
            "Overall - Precision: 0.7797 | Recall: 0.6479 | F1: 0.7077\n",
            "================================================================================\n",
            "EPOCH [135/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0263 | Val Loss: 66.2490\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [136/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0045 | Val Loss: 69.5775\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [137/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0045 | Val Loss: 68.8452\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [138/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0043 | Val Loss: 64.0368\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [139/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0091 | Val Loss: 65.6845\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [140/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0183 | Val Loss: 67.0779\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [141/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0103 | Val Loss: 69.3034\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [142/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1153 | Val Loss: 69.2940\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [143/200]\n",
            "================================================================================\n",
            "Train Loss: 0.8717 | Val Loss: 60.6637\n",
            "Overall - Precision: 0.7119 | Recall: 0.5915 | F1: 0.6462\n",
            "================================================================================\n",
            "EPOCH [144/200]\n",
            "================================================================================\n",
            "Train Loss: 1.4713 | Val Loss: 89.9067\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [145/200]\n",
            "================================================================================\n",
            "Train Loss: 1.1258 | Val Loss: 92.7473\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [146/200]\n",
            "================================================================================\n",
            "Train Loss: 1.4669 | Val Loss: 85.0818\n",
            "Overall - Precision: 0.7241 | Recall: 0.5915 | F1: 0.6512\n",
            "================================================================================\n",
            "EPOCH [147/200]\n",
            "================================================================================\n",
            "Train Loss: 1.2121 | Val Loss: 86.8335\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [148/200]\n",
            "================================================================================\n",
            "Train Loss: 0.6636 | Val Loss: 83.4564\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [149/200]\n",
            "================================================================================\n",
            "Train Loss: 0.3534 | Val Loss: 83.4289\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [150/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2596 | Val Loss: 80.8974\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [151/200]\n",
            "================================================================================\n",
            "Train Loss: 0.4491 | Val Loss: 74.0267\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [152/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1029 | Val Loss: 76.9523\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [153/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0610 | Val Loss: 76.6721\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [154/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2400 | Val Loss: 78.5214\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [155/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1249 | Val Loss: 81.4899\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [156/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0326 | Val Loss: 78.5066\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [157/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0120 | Val Loss: 80.4606\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [158/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0193 | Val Loss: 78.1155\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [159/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0120 | Val Loss: 81.9068\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [160/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0255 | Val Loss: 86.2087\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [161/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0132 | Val Loss: 81.9698\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [162/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0062 | Val Loss: 84.4080\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [163/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0385 | Val Loss: 80.4302\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [164/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0339 | Val Loss: 74.7775\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [165/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1173 | Val Loss: 77.8536\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [166/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0336 | Val Loss: 76.5387\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [167/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0102 | Val Loss: 75.3259\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [168/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0172 | Val Loss: 78.6514\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [169/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0124 | Val Loss: 81.3255\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [170/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0067 | Val Loss: 82.8308\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [171/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1000 | Val Loss: 77.7200\n",
            "Overall - Precision: 0.7931 | Recall: 0.6479 | F1: 0.7132\n",
            "================================================================================\n",
            "EPOCH [172/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1957 | Val Loss: 81.0909\n",
            "Overall - Precision: 0.8103 | Recall: 0.6620 | F1: 0.7287\n",
            "================================================================================\n",
            "EPOCH [173/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2345 | Val Loss: 91.9953\n",
            "Overall - Precision: 0.6949 | Recall: 0.5775 | F1: 0.6308\n",
            "================================================================================\n",
            "EPOCH [174/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0869 | Val Loss: 87.3140\n",
            "Overall - Precision: 0.6897 | Recall: 0.5634 | F1: 0.6202\n",
            "================================================================================\n",
            "EPOCH [175/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0665 | Val Loss: 85.9524\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [176/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0095 | Val Loss: 82.6129\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [177/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0129 | Val Loss: 85.2911\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [178/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0120 | Val Loss: 82.3800\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [179/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0033 | Val Loss: 80.4602\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [180/200]\n",
            "================================================================================\n",
            "Train Loss: 0.1115 | Val Loss: 94.1693\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [181/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0508 | Val Loss: 97.2662\n",
            "Overall - Precision: 0.7241 | Recall: 0.5915 | F1: 0.6512\n",
            "================================================================================\n",
            "EPOCH [182/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0249 | Val Loss: 97.4577\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [183/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0120 | Val Loss: 93.5735\n",
            "Overall - Precision: 0.6897 | Recall: 0.5634 | F1: 0.6202\n",
            "================================================================================\n",
            "EPOCH [184/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0353 | Val Loss: 94.7451\n",
            "Overall - Precision: 0.7241 | Recall: 0.5915 | F1: 0.6512\n",
            "================================================================================\n",
            "EPOCH [185/200]\n",
            "================================================================================\n",
            "Train Loss: 1.1422 | Val Loss: 78.2916\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [186/200]\n",
            "================================================================================\n",
            "Train Loss: 0.5992 | Val Loss: 84.8321\n",
            "Overall - Precision: 0.7069 | Recall: 0.5775 | F1: 0.6357\n",
            "================================================================================\n",
            "EPOCH [187/200]\n",
            "================================================================================\n",
            "Train Loss: 0.7687 | Val Loss: 72.9548\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [188/200]\n",
            "================================================================================\n",
            "Train Loss: 0.9109 | Val Loss: 74.2791\n",
            "Overall - Precision: 0.7759 | Recall: 0.6338 | F1: 0.6977\n",
            "================================================================================\n",
            "EPOCH [189/200]\n",
            "================================================================================\n",
            "Train Loss: 1.1863 | Val Loss: 99.7908\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [190/200]\n",
            "================================================================================\n",
            "Train Loss: 1.8558 | Val Loss: 76.4748\n",
            "Overall - Precision: 0.7241 | Recall: 0.5915 | F1: 0.6512\n",
            "================================================================================\n",
            "EPOCH [191/200]\n",
            "================================================================================\n",
            "Train Loss: 0.5106 | Val Loss: 95.1752\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [192/200]\n",
            "================================================================================\n",
            "Train Loss: 0.3156 | Val Loss: 104.2839\n",
            "Overall - Precision: 0.7241 | Recall: 0.5915 | F1: 0.6512\n",
            "================================================================================\n",
            "EPOCH [193/200]\n",
            "================================================================================\n",
            "Train Loss: 0.7817 | Val Loss: 88.6960\n",
            "Overall - Precision: 0.7241 | Recall: 0.5915 | F1: 0.6512\n",
            "================================================================================\n",
            "EPOCH [194/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2594 | Val Loss: 91.4669\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [195/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0347 | Val Loss: 89.3671\n",
            "Overall - Precision: 0.7018 | Recall: 0.5634 | F1: 0.6250\n",
            "================================================================================\n",
            "EPOCH [196/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0426 | Val Loss: 96.0853\n",
            "Overall - Precision: 0.7368 | Recall: 0.5915 | F1: 0.6562\n",
            "================================================================================\n",
            "EPOCH [197/200]\n",
            "================================================================================\n",
            "Train Loss: 0.5220 | Val Loss: 84.6129\n",
            "Overall - Precision: 0.7586 | Recall: 0.6197 | F1: 0.6822\n",
            "================================================================================\n",
            "EPOCH [198/200]\n",
            "================================================================================\n",
            "Train Loss: 0.2156 | Val Loss: 86.8251\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [199/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0074 | Val Loss: 93.1428\n",
            "Overall - Precision: 0.7414 | Recall: 0.6056 | F1: 0.6667\n",
            "================================================================================\n",
            "EPOCH [200/200]\n",
            "================================================================================\n",
            "Train Loss: 0.0090 | Val Loss: 92.7925\n",
            "Overall - Precision: 0.7241 | Recall: 0.5915 | F1: 0.6512\n",
            "âœ” Model terbaik disimpan dengan F1-Score: 0.7442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def entity_score_to_df(entity_score_dict, ix_to_tag):\n",
        "    rows = []\n",
        "\n",
        "    for label_ix, scores in entity_score_dict.items():\n",
        "        rows.append({\n",
        "            \"Entity\": ix_to_tag[label_ix],\n",
        "            \"TP\": scores[\"TP\"],\n",
        "            \"FP\": scores[\"FP\"],\n",
        "            \"FN\": scores[\"FN\"],\n",
        "            \"Precision\": round(scores[\"Precision\"], 4),\n",
        "            \"Recall\": round(scores[\"Recall\"], 4),\n",
        "            \"F1-Score\": round(scores[\"F1-Score\"], 4),\n",
        "            \"Support\": scores[\"Support\"]\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Urutkan biar rapi\n",
        "    df = df.sort_values(\"Entity\").reset_index(drop=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "fNFcvSjm-JZi"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = entity_score_to_df(score_dict, ix_to_tag)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "9aPKBAM5R1gI",
        "outputId": "4d6b029b-afc1-4f7c-caac-e770e4a1f126"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Entity  TP  FP  FN  Precision  Recall  F1-Score  Support\n",
              "0   FIS-NEG   2   3   2     0.4000  0.5000    0.4444        4\n",
              "1   FIS-POS   0   2   2     0.0000  0.0000    0.0000        2\n",
              "2   HWN-NEG   8   4   2     0.6667  0.8000    0.7273       10\n",
              "3   HWN-POS   1   2   2     0.3333  0.3333    0.3333        3\n",
              "4   PER-NEG  10   4   4     0.7143  0.7143    0.7143       14\n",
              "5   PER-POS   0   1   3     0.0000  0.0000    0.0000        3\n",
              "6  SEKS-NEG  21   0  14     1.0000  0.6000    0.7500       35"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d50d434-b0b3-4a93-ac01-9b24b3c50a5f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Entity</th>\n",
              "      <th>TP</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FIS-NEG</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.4444</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FIS-POS</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HWN-NEG</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7273</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HWN-POS</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PER-NEG</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.7143</td>\n",
              "      <td>0.7143</td>\n",
              "      <td>0.7143</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PER-POS</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SEKS-NEG</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d50d434-b0b3-4a93-ac01-9b24b3c50a5f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d50d434-b0b3-4a93-ac01-9b24b3c50a5f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d50d434-b0b3-4a93-ac01-9b24b3c50a5f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7d6cdc65-edc7-4005-a65f-dad0f37c2a77\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d6cdc65-edc7-4005-a65f-dad0f37c2a77')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7d6cdc65-edc7-4005-a65f-dad0f37c2a77 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8987d9d9-7995-48ef-9ef0-55c7f2f875dc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8987d9d9-7995-48ef-9ef0-55c7f2f875dc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result",
              "summary": "{\n  \"name\": \"result\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Entity\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"FIS-NEG\",\n          \"FIS-POS\",\n          \"PER-POS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 21,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          0,\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2,\n        \"max\": 14,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          14,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.37422145849750516,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.4,\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32406818433045553,\n        \"min\": 0.0,\n        \"max\": 0.8,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5,\n          0.0,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32932643090896624,\n        \"min\": 0.0,\n        \"max\": 0.75,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.4444,\n          0.0,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 2,\n        \"max\": 35,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          2,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity Check"
      ],
      "metadata": {
        "id": "aGJL4cnkKW4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"best_model.sav\", map_location=device)\n",
        "\n",
        "reloaded_model = BiLSTM_Attend_CRF(\n",
        "    checkpoint[\"pad_ix\"],\n",
        "    checkpoint[\"tag_size\"],\n",
        "    checkpoint[\"vocab_size\"],\n",
        "    checkpoint[\"hidden_size\"],\n",
        "    checkpoint[\"embedding_dim\"],\n",
        "    heads=checkpoint[\"heads\"]\n",
        ").to(device)\n",
        "\n",
        "reloaded_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "print(\"âœ” Model successfully loaded\")"
      ],
      "metadata": {
        "id": "6-THtFBtOay5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67254b9-9246-4be2-819f-438370df39b4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ” Model successfully loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentence(sentence, model, word_to_ix, ix_to_tag, device):\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = sentence.lower().split()\n",
        "\n",
        "    # Map tokens to indices (use <UNK> for unseen words)\n",
        "    indexed_tokens = [\n",
        "        word_to_ix.get(tok, word_to_ix[\"<UNK>\"])\n",
        "        for tok in tokens\n",
        "    ]\n",
        "\n",
        "    # Convert to tensor and add batch dimension\n",
        "    # Shape: (1, sequence_length)\n",
        "    input_tensor = torch.tensor(\n",
        "        indexed_tokens,\n",
        "        dtype=torch.long\n",
        "    ).unsqueeze(0).to(device)\n",
        "\n",
        "    # Create mask to ignore padding tokens\n",
        "    mask = input_tensor.ne(0)\n",
        "\n",
        "    # Decode the best tag sequence using CRF\n",
        "    with torch.no_grad():\n",
        "        predicted_tags = model.crf_decode(\n",
        "            inp=input_tensor,\n",
        "            mask=mask\n",
        "        )[0]\n",
        "\n",
        "    # Convert tag indices back to label names\n",
        "    predicted_labels = [\n",
        "        ix_to_tag[tag_ix] for tag_ix in predicted_tags\n",
        "    ]\n",
        "    # Return token-label pairs\n",
        "    return list(zip(tokens, predicted_labels))\n"
      ],
      "metadata": {
        "id": "nMiMohy-Kbqw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Jangan gitu anjing lah\"\n",
        "\n",
        "result = predict_sentence(\n",
        "    sentence=sentence,\n",
        "    model=reloaded_model,\n",
        "    word_to_ix=word_to_ix,\n",
        "    ix_to_tag=ix_to_tag,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "for word, label in result:\n",
        "    print(f\"{word:<12} -> {label}\")"
      ],
      "metadata": {
        "id": "zKgD3QY4KlpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b342610f-7ce6-43a7-9991-f67775987559"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jangan       -> O\n",
            "gitu         -> O\n",
            "anjing       -> HWN-NEG\n",
            "lah          -> O\n"
          ]
        }
      ]
    }
  ]
}